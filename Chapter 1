Chapter 1

Importing the data
Welcome! This course will give you some additional practice with importing and cleaning data through a series of four case studies. We’re assuming you’ve already completed these four courses:
Intro to R
Intermediate R
Importing Data Into R
Cleaning Data in R
If not, you’ll want to check those out first.
You'll be importing and cleaning four real datasets that are a little messier than before. Don't worry -- you're up for the challenge!
Your first dataset describes online ticket sales for various events across the country. It's stored as a Comma-Separated Value (CSV) file called sales.csv. Let's jump right in!

Import sales.csv to the variable sales using the read.csv() function. Set the stringsAsFactors argument to FALSE so that character strings are preserved.
# Import sales.csv: sales
sales <- read.csv("sales.csv", stringsAsFactors = FALSE)
_____________________________________________________________________________________

Examining the data
As you know from the Cleaning Data in R course, the first step when preparing to clean data is to inspect it. Let's refresh your memory on some useful functions that can do that:
dim() returns the dimensions of an object
head() displays the first part of an object
names() returns the names associated with an object

The sales data frame you created in the last exercise is pre-loaded in your workspace.

View the dimensions of your new sales data frame.
Inspect the first 6 rows of sales.
View the column names of sales.
# View dimensions of sales
dim(sales)

# Inspect first 6 rows of sales
head(sales)

# View column names of sales
names(sales)
_____________________________________________________________________________________

Summarizing the data
Luckily, the rows and columns appear to be arranged in a meaningful way: each row represents an observation and each column a variable, or piece of information about that observation.
In R, there are a great many tools at your disposal to help get a feel for your data. Besides the three you used in the previous exercise, the functions str() and summary() can be very helpful.
The dplyr package, introduced in Cleaning Data in R, offers the glimpse() function, which can also be used for this purpose. The package is already installed on DataCamp; you just need to load it.

Look at the structure of sales.
View a summary of your data.
Load the dplyr package.
Use glimpse() to look at your data.
# Look at structure of sales
str(sales)
# View a summary of sales
summary(sales)
# Load dplyr
library(dplyr)
# Get a glimpse of sales
glimpse(sales)
_____________________________________________________________________________________
Removing redundant info
You may have noticed that the first column of data is just a duplication of the row numbers. Not very useful. Go ahead and delete that column.
Remember that nrow() and ncol() return the number of rows and columns in a data frame, respectively.
Also, recall that you can use square brackets to subset a data frame as follows:
my_df[1:5, ] # First 5 rows of my_df
my_df[, 4]   # Fourth column of my_df


Alternatively, you can remove rows and columns using negative indices. For example:
my_df[-(1:5), ] # Omit first 5 rows of my_df
my_df[, -4]     # Omit fourth column of my_df


Take a subset of sales to omit the first column. Assign the result to sales2.
## sales is available in your workspace
# Remove the first column of sales: sales2
sales2 <- sales[, -(1)]
_____________________________________________________________________________________


Information not worth keeping
Many of the columns have information that's of no use to us. For example, the first four columns contain internal codes representing particular events. The last fifteen columns also aren't worth keeping; there are too many missing values to make them worthwhile.
An easy way to get rid of unnecessary columns is to create a vector containing the column indices 
Create a vector called keep that contains the indices of the columns you want to save. Remember: you want to keep everything besides the first 4 and last 15 columns of sales2.
Subset the columns of sales2 using your vector and assign the result to sales3.
## sales2 is available in your workspace
# Define a vector of column indices: keep
keep <- c(5 : (ncol(sales2) - 15))
# Subset sales2 using keep: sales3
sales3 <- sales2[keep]
_____________________________________________________________________________________
Separating columns
Some of the columns in your data frame include multiple pieces of information that should be in separate columns. In this exercise, you will separate such a column into two: one for date and one for time. You will use the separate()function from the tidyr package (already installed for you).
Take a look at the event_date_time column by typing head(sales3$event_date_time) in the console. You'll notice that the date and time are separated by a space. Therefore, you'll use sep = " " as an argument to separate().

Load the tidyr package.
Split the event_date_time column of sales3 into "event_dt" and "event_time". Assign the result to sales4.
Split the sales_ord_create_dttm column of sales4into "ord_create_dt" and "ord_create_time". Assign the result to sales5.
## sales3 is pre-loaded in your workspace
# Load tidyr
library(tidyr)

# Split event_date_time: sales4
sales4 <- separate(sales3, event_date_time, c("event_dt", "event_time"), sep = " ")

# Split sales_ord_create_dttm: sales5
sales5 <- separate(sales4, sales_ord_create_dttm, c("ord_create_dt", "ord_create_time"), sep = " ")
_____________________________________________________________________________________
Dealing with warnings
Looks like that second call to separate() threw a warning. Not to worry; warnings aren't as bad as error messages. It's not saying that the command didn't execute; it's just a heads-up that something unusual happened.
The warning says Too few values at 4 locations. You may be able to guess already what the issue is, but it's still good to take a look.
The locations (i.e. rows) given in the warning are 2516, 3863, 4082, and 4183. Have a look at the contents of the sales_ord_create_dttmcolumn in those rows.

Assign a vector issues that contains the indices of the four troublesome rows: 2516, 3863, 4082, and 4183.
Subset sales3$sales_ord_create_dttmto look at these observations. Remember to use sales3 (not sales4), since you want the data frame from before you separated columns!
For comparison, print element 2517 of sales3$sales_ord_create_dttm, which did not cause a warning.
# Define an issues vector
issues <- c(2516, 3863, 4082, 4183)

# Print values of sales_ord_create_dttm at these indices
sales3$sales_ord_create_dttm[issues]

# Print a well-behaved value of sales_ord_create_dttm
sales3$sales_ord_create_dttm[2517]
_____________________________________________________________________________________
Identifying dates
Some of the columns in your dataset contain dates of different events. Right now, they are stored as character strings. That's fine if all you want to do is look up the date associated with an event, but if you want to do any comparisons or math with the dates, it's MUCH easier to store them as Date objects.
Luckily, all of the date columns in this dataset have the substring "dt" in their name, so you can use the str_detect() function of the stringr package to find the date columns. Then you can coerce them to Date objects using a function from the lubridate package.
You'll use lapply() to apply the appropriate lubridate function to all of the columns that contain dates. Recall the following syntax for lapply() applied to some data frame columns of interest:
lapply(my_data_frame[, cols], function_name)


Also recall that function names in lubridate combine the letters y, m, d, h, m, and s depending on the format of the date/time string being read in.

Load the stringr package.
Use str_detect() to find values in the names() of sales5 containing the string "dt". Assign the resulting logical vector to the variable date_cols.
Load the lubridate package.
Coerce the date_cols into Date objects using lapply() and the appropriate function from lubridate. Conveniently, all date columns in sales5 are in year-month-day format, so you can use the ymd() function from lubridate.
## sales5 is pre-loaded
# Load stringr
library(stringr)
# Find columns of sales5 containing "dt": date_cols
date_cols <- str_detect(names(sales5), "dt")
# Load lubridate
library(lubridate)
# Coerce date columns into Date objects
sales5[, date_cols] <- lapply(sales5[, date_cols], ymd)
_____________________________________________________________________________________
More warnings!
As you saw, some of the calls to ymd() caused a failure to parsewarning. That's probably because of more missing data, but again, it's good to check to be sure.
The first two lines of code (provided for you here) create a list of logical vectors called missing. Each vector in the list indicates the presence (or absence) of missing values in the corresponding column of sales5. See if the number of missing values in each column is the same as the number of rows that failed to parse in the previous exercise.
As a reminder, here are the warning messages:
Warning message:  2892 failed to parse.
Warning message:  101 failed to parse.
Warning message:  4 failed to parse.
Warning message:  424 failed to parse.

Run the first line as-is to regenerate the date_cols vector.
Run the second line as-is to generate a list of logical vectors representing missing values in the date columns of sales5.
Use sapply() to create a numerical vector containing the number of NA values in each date column. Call this vector num_missing.
Print out the num_missing vector.
## stringr is loaded
# Find date columns (don't change)
date_cols <- str_detect(names(sales5), "dt")

# Create logical vectors indicating missing values (don't change)
missing <- lapply(sales5[, date_cols], is.na)

# Create a numerical vector that counts missing values: num_missing
num_missing <- sapply(missing, sum)

# Print num_missing
num_missing
_____________________________________________________________________________________
Combining columns
Sure enough, the number of NAs in each column match the numbers from the warning messages, so missing data is the culprit. How to proceed depends on your desired analysis. If you really need complete sets of date/time information, you might delete the rows or columns containing NAs.
As your last step, you'll use the tidyr function unite() to combine the venue_city and venue_state columns into one column with the two values separated by a comma and a space. For example, "PORTLAND" "MAINE" should become "PORTLAND, MAINE".

Combine the venue_city and venue_state columns of sales5 into a new column called venue_city_state, containing the city and state names separated by a comma and a space. Call the resulting data frame sales6.
View the first 6 rows of sales6.
## tidyr is loaded

# Combine the venue_city and venue_state columns
sales6 <- unite(sales5, venue_city_state, venue_city, venue_state, sep=", ")

# View the head of sales6
head(sales6)
_____________________________________________________________________________________











